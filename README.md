# Projet de Scoring de CrÃ©dit

Projet complet de machine learning pour la prÃ©diction du remboursement de crÃ©dit, incluant l'entraÃ®nement d'un modÃ¨le XGBoost, une API REST Flask, et la containerisation Docker.

## ğŸ“‹ Description

Ce projet vise Ã  prÃ©dire la probabilitÃ© de remboursement d'un prÃªt en utilisant des techniques de machine learning. Il comprend :

- **Analyse et prÃ©paration des donnÃ©es** : Exploration et preprocessing des donnÃ©es de crÃ©dit
- **EntraÃ®nement du modÃ¨le** : DÃ©veloppement d'un modÃ¨le XGBoost pour la classification
- **API REST** : Service web Flask pour exposer le modÃ¨le en production
- **Containerisation** : DÃ©ploiement avec Docker
- **Tests** : Suite de tests unitaires pour l'API

## ğŸ—ï¸ Structure du projet

```
DevOps/
â”œâ”€â”€ api/                          # Application Flask
â”‚   â”œâ”€â”€ app.py                    # Application Flask principale
â”‚   â””â”€â”€ model_loader.py           # Chargement du modÃ¨le XGBoost
â”œâ”€â”€ data/                         # DonnÃ©es brutes
â”‚   â””â”€â”€ data.csv                  # Dataset de crÃ©dit
â”œâ”€â”€ model/                        # ModÃ¨les entraÃ®nÃ©s
â”‚   â””â”€â”€ xgboost_credit_scoring_final.json
â”œâ”€â”€ notebooks/                    # Notebooks d'analyse et d'entraÃ®nement
â”‚   â””â”€â”€ model_train.ipynb         # Notebook d'entraÃ®nement du modÃ¨le
â”œâ”€â”€ docker/                       # Configuration Docker
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ tests/                        # Tests unitaires
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ docs/                         # Documentation et captures d'Ã©cran
â”œâ”€â”€ requirements.txt              # DÃ©pendances Python
â””â”€â”€ README.md
```

## ğŸ”§ PrÃ©requis

- Python 3.11+
- Jupyter Notebook (pour l'exploration et l'entraÃ®nement)
- Docker (optionnel, pour la containerisation)

## ğŸš€ Installation

1. **Cloner le projet**

2. **CrÃ©er un environnement virtuel** :
```bash
python -m venv env
source env/bin/activate  # Sur Windows: env\Scripts\activate
```

3. **Installer les dÃ©pendances** :
```bash
pip install -r requirements.txt
```

## ğŸ“Š DonnÃ©es

Le dataset contient des informations sur les prÃªts avec les variables suivantes :

- **Variables numÃ©riques** : `annual_income`, `debt_to_income_ratio`, `credit_score`, `loan_amount`, `interest_rate`
- **Variables catÃ©gorielles** : `gender`, `marital_status`, `education_level`, `employment_status`, `loan_purpose`, `grade_subgrade`
- **Variable cible** : `loan_paid_back` (1 = remboursÃ©, 0 = non remboursÃ©)

Les donnÃ©es sont stockÃ©es dans `data/data.csv`.

## ğŸ“ EntraÃ®nement du modÃ¨le

### PrÃ©processing

Le notebook `notebooks/model_train.ipynb` contient :

1. **Exploration des donnÃ©es** : Analyse descriptive et visualisations
2. **Encodage des variables catÃ©gorielles** :
   - Encodage ordinal pour `education_level` et `grade_subgrade`
   - Encodage one-hot pour `gender`, `marital_status`, `employment_status`, `loan_purpose`
3. **Normalisation** : Standardisation des variables numÃ©riques avec `StandardScaler`
4. **Division train/test** : SÃ©paration des donnÃ©es (90% train, 10% test)

### ModÃ¨le

- **Algorithme** : XGBoost Classifier
- **Features** : 23 features aprÃ¨s preprocessing
- **Format de sauvegarde** : JSON

### ExÃ©cuter l'entraÃ®nement

```bash
# Ouvrir le notebook Jupyter
jupyter notebook notebooks/model_train.ipynb
```

Le modÃ¨le entraÃ®nÃ© est sauvegardÃ© dans `model/xgboost_credit_scoring_final.json`.

## ğŸ’» Utilisation de l'API

### Lancer l'API localement

```bash
cd api
python app.py
```

L'API sera accessible sur `http://localhost:5000`

### Utilisation avec Docker

1. **Construire l'image** :
```bash
docker build -f docker/Dockerfile -t credit-scoring-api .
```

2. **Lancer le conteneur** :
```bash
docker run -p 5000:5000 credit-scoring-api
```

3. **Lancer en arriÃ¨re-plan** :
```bash
docker run -d -p 5000:5000 --name credit-api credit-scoring-api
```

## ğŸ“¡ Endpoints API

### `GET /health`
VÃ©rifie le statut de l'API et du modÃ¨le.

**RÃ©ponse :**
```json
{
  "status": "online",
  "model": "XGBoost_v1"
}
```

### `POST /predict`
Effectue une prÃ©diction de remboursement.

**Corps de la requÃªte (JSON)** - 23 features requises :
```json
{
  "annual_income": 0.5,
  "debt_to_income_ratio": -0.3,
  "credit_score": 0.8,
  "loan_amount": -0.2,
  "interest_rate": 0.1,
  "education_level_ord": 1,
  "grade_subgrade_le": 10,
  "gender_Male": 0.0,
  "gender_Other": 0.0,
  "marital_status_Married": 1.0,
  "marital_status_Single": 0.0,
  "marital_status_Widowed": 0.0,
  "employment_status_Retired": 0.0,
  "employment_status_Self-employed": 0.0,
  "employment_status_Student": 0.0,
  "employment_status_Unemployed": 0.0,
  "loan_purpose_Car": 0.0,
  "loan_purpose_Debt consolidation": 0.0,
  "loan_purpose_Education": 0.0,
  "loan_purpose_Home": 1.0,
  "loan_purpose_Medical": 0.0,
  "loan_purpose_Other": 0.0,
  "loan_purpose_Vacation": 0.0
}
```

**RÃ©ponse :**
```json
{
  "status": "success",
  "probability_of_repayment": 0.8542,
  "decision": "Approved",
  "class_id": 1
}
```

**Exemple avec curl** :
```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "annual_income": 0.5,
    "debt_to_income_ratio": -0.3,
    "credit_score": 0.8,
    "loan_amount": -0.2,
    "interest_rate": 0.1,
    "education_level_ord": 1,
    "grade_subgrade_le": 10,
    "gender_Male": 0.0,
    "gender_Other": 0.0,
    "marital_status_Married": 1.0,
    "marital_status_Single": 0.0,
    "marital_status_Widowed": 0.0,
    "employment_status_Retired": 0.0,
    "employment_status_Self-employed": 0.0,
    "employment_status_Student": 0.0,
    "employment_status_Unemployed": 0.0,
    "loan_purpose_Car": 0.0,
    "loan_purpose_Debt consolidation": 0.0,
    "loan_purpose_Education": 0.0,
    "loan_purpose_Home": 1.0,
    "loan_purpose_Medical": 0.0,
    "loan_purpose_Other": 0.0,
    "loan_purpose_Vacation": 0.0
  }'
```

## ğŸ§ª Tests

ExÃ©cuter les tests unitaires de l'API :

```bash
python -m unittest tests.test_api -v
```

Les tests couvrent :
- Endpoint `/health`
- Endpoint `/predict` avec donnÃ©es valides
- Gestion des erreurs (donnÃ©es manquantes, JSON invalide)
- Validation des mÃ©thodes HTTP

## ğŸ“¦ DÃ©pendances principales

- **Flask 3.1.2** : Framework web
- **XGBoost 3.1.2** : ModÃ¨le de machine learning
- **pandas 2.3.3** : Manipulation de donnÃ©es
- **scikit-learn 1.8.0** : Preprocessing et outils ML
- **numpy 2.4.0** : Calculs numÃ©riques
- **scipy 1.16.3** : Outils scientifiques

## ğŸ” Workflow complet

1. **Exploration** : Analyser les donnÃ©es dans `notebooks/model_train.ipynb`
2. **Preprocessing** : PrÃ©parer les donnÃ©es (encodage, normalisation)
3. **EntraÃ®nement** : EntraÃ®ner le modÃ¨le XGBoost
4. **Sauvegarde** : Sauvegarder le modÃ¨le dans `model/`
5. **API** : Exposer le modÃ¨le via l'API Flask
6. **DÃ©ploiement** : Containeriser avec Docker
7. **Tests** : Valider le fonctionnement avec les tests unitaires

## ğŸ“ Notes importantes

- Le modÃ¨le attend **23 features prÃ©-traitÃ©es** (normalisÃ©es et encodÃ©es)
- Les donnÃ©es doivent Ãªtre au format JSON avec **toutes les colonnes requises**
- Le modÃ¨le est chargÃ© au dÃ©marrage de l'API
- Les variables numÃ©riques doivent Ãªtre normalisÃ©es (StandardScaler)
- Les variables catÃ©gorielles doivent Ãªtre encodÃ©es (one-hot avec drop='first')

## ğŸ“š Documentation

Des captures d'Ã©cran et de la documentation supplÃ©mentaire sont disponibles dans le dossier `docs/`.