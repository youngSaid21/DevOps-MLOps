# Projet de Scoring de CrÃ©dit

Projet complet de machine learning pour la prÃ©diction du remboursement de crÃ©dit, incluant l'entraÃ®nement d'un modÃ¨le XGBoost, une API REST Flask, la containerisation Docker, et le dÃ©ploiement automatique sur AWS EC2 avec CI/CD.

## ğŸ“‹ Description

Ce projet vise Ã  prÃ©dire la probabilitÃ© de remboursement d'un prÃªt en utilisant des techniques de machine learning. Il comprend :

- **Analyse et prÃ©paration des donnÃ©es** : Exploration et preprocessing des donnÃ©es de crÃ©dit
- **EntraÃ®nement du modÃ¨le** : DÃ©veloppement d'un modÃ¨le XGBoost pour la classification
- **API REST** : Service web Flask pour exposer le modÃ¨le en production
- **Containerisation** : DÃ©ploiement avec Docker
- **Tests** : Suite de tests unitaires pour l'API
- **CI/CD** : IntÃ©gration continue avec GitHub Actions
- **DÃ©ploiement automatique** : DÃ©ploiement automatique sur AWS EC2 Ã  chaque push

## ğŸ—ï¸ Structure du projet

```
DevOps-MLOps/
â”œâ”€â”€ api/                          # Application Flask
â”‚   â”œâ”€â”€ app.py                    # Application Flask principale
â”‚   â””â”€â”€ model_loader.py           # Chargement du modÃ¨le XGBoost
â”œâ”€â”€ data/                         # DonnÃ©es brutes
â”‚   â””â”€â”€ data.csv                  # Dataset de crÃ©dit
â”œâ”€â”€ model/                        # ModÃ¨les entraÃ®nÃ©s
â”‚   â””â”€â”€ xgboost_credit_scoring_final.json
â”œâ”€â”€ notebooks/                    # Notebooks d'analyse et d'entraÃ®nement
â”‚   â””â”€â”€ model_train.ipynb         # Notebook d'entraÃ®nement du modÃ¨le
â”œâ”€â”€ docker/                       # Configuration Docker
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ tests/                        # Tests unitaires
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ .github/                      # Configuration GitHub Actions
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml                # Workflow CI (tests)
â”‚       â””â”€â”€ deploy.yml             # Workflow CD (dÃ©ploiement)
â”œâ”€â”€ docs/                         # Documentation et captures d'Ã©cran
â”œâ”€â”€ deploy.sh                     # Script de dÃ©ploiement pour EC2
â”œâ”€â”€ requirements.txt              # DÃ©pendances Python
â””â”€â”€ README.md
```

## ğŸ”§ PrÃ©requis

- Python 3.11+
- Jupyter Notebook (pour l'exploration et l'entraÃ®nement)
- Docker (pour la containerisation)
- Compte AWS avec instance EC2 (pour le dÃ©ploiement)
- Compte GitHub (pour CI/CD)

## ğŸš€ Installation

1. **Cloner le projet**

2. **CrÃ©er un environnement virtuel** :
```bash
python -m venv env
source env/bin/activate  # Sur Windows: env\Scripts\activate
```

3. **Installer les dÃ©pendances** :
```bash
pip install -r requirements.txt
```

## ğŸ“Š DonnÃ©es

Le dataset contient des informations sur les prÃªts avec les variables suivantes :

- **Variables numÃ©riques** : `annual_income`, `debt_to_income_ratio`, `credit_score`, `loan_amount`, `interest_rate`
- **Variables catÃ©gorielles** : `gender`, `marital_status`, `education_level`, `employment_status`, `loan_purpose`, `grade_subgrade`
- **Variable cible** : `loan_paid_back` (1 = remboursÃ©, 0 = non remboursÃ©)

Les donnÃ©es sont stockÃ©es dans `data/data.csv`.

## ğŸ“ EntraÃ®nement du modÃ¨le

### PrÃ©processing

Le notebook `notebooks/model_train.ipynb` contient :

1. **Exploration des donnÃ©es** : Analyse descriptive et visualisations
2. **Encodage des variables catÃ©gorielles** :
   - Encodage ordinal pour `education_level` et `grade_subgrade`
   - Encodage one-hot pour `gender`, `marital_status`, `employment_status`, `loan_purpose`
3. **Normalisation** : Standardisation des variables numÃ©riques avec `StandardScaler`
4. **Division train/test** : SÃ©paration des donnÃ©es (90% train, 10% test)

### ModÃ¨le

- **Algorithme** : XGBoost Classifier
- **Features** : 23 features aprÃ¨s preprocessing
- **Format de sauvegarde** : JSON

### ExÃ©cuter l'entraÃ®nement

```bash
# Ouvrir le notebook Jupyter
jupyter notebook notebooks/model_train.ipynb
```

Le modÃ¨le entraÃ®nÃ© est sauvegardÃ© dans `model/xgboost_credit_scoring_final.json`.

## ğŸ’» Utilisation de l'API

### Lancer l'API localement

```bash
cd api
python app.py
```

L'API sera accessible sur `http://localhost:5000`

### Utilisation avec Docker

1. **Construire l'image** :
```bash
docker build -f docker/Dockerfile -t credit-scoring-api .
```

2. **Lancer le conteneur** :
```bash
docker run -p 5000:5000 credit-scoring-api
```

3. **Lancer en arriÃ¨re-plan** :
```bash
docker run -d -p 5000:5000 --name credit-api credit-scoring-api
```

## ğŸ“¡ Endpoints API

### `GET /health`
VÃ©rifie le statut de l'API et du modÃ¨le.

**RÃ©ponse :**
```json
{
  "status": "online",
  "model": "XGBoost_v1"
}
```

### `POST /predict`
Effectue une prÃ©diction de remboursement.

**Corps de la requÃªte (JSON)** - 23 features requises :
```json
{
  "annual_income": 0.5,
  "debt_to_income_ratio": -0.3,
  "credit_score": 0.8,
  "loan_amount": -0.2,
  "interest_rate": 0.1,
  "education_level_ord": 1,
  "grade_subgrade_le": 10,
  "gender_Male": 0.0,
  "gender_Other": 0.0,
  "marital_status_Married": 1.0,
  "marital_status_Single": 0.0,
  "marital_status_Widowed": 0.0,
  "employment_status_Retired": 0.0,
  "employment_status_Self-employed": 0.0,
  "employment_status_Student": 0.0,
  "employment_status_Unemployed": 0.0,
  "loan_purpose_Car": 0.0,
  "loan_purpose_Debt consolidation": 0.0,
  "loan_purpose_Education": 0.0,
  "loan_purpose_Home": 1.0,
  "loan_purpose_Medical": 0.0,
  "loan_purpose_Other": 0.0,
  "loan_purpose_Vacation": 0.0
}
```

**RÃ©ponse :**
```json
{
  "status": "success",
  "probability_of_repayment": 0.8542,
  "decision": "Approved",
  "class_id": 1
}
```

**Exemple avec curl (local)** :
```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "annual_income": 0.5,
    "debt_to_income_ratio": -0.3,
    "credit_score": 0.8,
    "loan_amount": -0.2,
    "interest_rate": 0.1,
    "education_level_ord": 1,
    "grade_subgrade_le": 10,
    "gender_Male": 0.0,
    "gender_Other": 0.0,
    "marital_status_Married": 1.0,
    "marital_status_Single": 0.0,
    "marital_status_Widowed": 0.0,
    "employment_status_Retired": 0.0,
    "employment_status_Self-employed": 0.0,
    "employment_status_Student": 0.0,
    "employment_status_Unemployed": 0.0,
    "loan_purpose_Car": 0.0,
    "loan_purpose_Debt consolidation": 0.0,
    "loan_purpose_Education": 0.0,
    "loan_purpose_Home": 1.0,
    "loan_purpose_Medical": 0.0,
    "loan_purpose_Other": 0.0,
    "loan_purpose_Vacation": 0.0
  }'
```

**Exemple avec curl (API dÃ©ployÃ©e sur EC2)** :
```bash
curl -X POST http://[VOTRE_IP_EC2]:5000/predict \
  -H "Content-Type: application/json" \
  -d '{...}'
```

## ğŸ§ª Tests

ExÃ©cuter les tests unitaires de l'API :

```bash
python -m unittest tests.test_api -v
```

Les tests couvrent :
- Endpoint `/health`
- Endpoint `/predict` avec donnÃ©es valides
- Gestion des erreurs (donnÃ©es manquantes, JSON invalide)
- Validation des mÃ©thodes HTTP

## ğŸ“¦ DÃ©pendances principales

- **Flask 3.1.2** : Framework web
- **XGBoost 3.1.2** : ModÃ¨le de machine learning
- **pandas 2.3.3** : Manipulation de donnÃ©es
- **scikit-learn 1.8.0** : Preprocessing et outils ML
- **numpy 2.4.0** : Calculs numÃ©riques
- **scipy 1.16.3** : Outils scientifiques

## ğŸš€ CI/CD et DÃ©ploiement Automatique

### GitHub Actions Workflows

Le projet utilise GitHub Actions pour l'intÃ©gration et le dÃ©ploiement continus :

#### Workflow CI (`.github/workflows/ci.yml`)
- **DÃ©clenchement** : Ã€ chaque push/PR sur `main`, `master`, ou `develop`
- **Tests** : ExÃ©cution des tests unitaires sur Python 3.11
- **Build Docker** : VÃ©rification que l'image Docker se construit correctement
- **Linting** : VÃ©rification du style de code (Black, isort, flake8)

#### Workflow CD (`.github/workflows/deploy.yml`)
- **DÃ©clenchement** : AprÃ¨s succÃ¨s du workflow CI sur `main` ou `master`
- **DÃ©ploiement** : Connexion SSH Ã  EC2 et dÃ©ploiement automatique
- **Processus** :
  1. Pull du code depuis GitHub
  2. Rebuild de l'image Docker
  3. RedÃ©marrage du conteneur
  4. VÃ©rification que l'API fonctionne

### Configuration du DÃ©ploiement Automatique

Pour activer le dÃ©ploiement automatique, configurez les secrets GitHub :

1. **Allez dans** : Repository â†’ Settings â†’ Secrets and variables â†’ Actions
2. **Ajoutez ces secrets** :
   - `EC2_HOST` : L'IP publique de votre instance EC2
   - `EC2_USER` : L'utilisateur SSH (gÃ©nÃ©ralement `ubuntu`)
   - `EC2_SSH_KEY` : Le contenu complet de votre clÃ© SSH `.pem`

### DÃ©ploiement Manuel sur EC2

Si vous prÃ©fÃ©rez dÃ©ployer manuellement :

```bash
# 1. Se connecter Ã  EC2
ssh -i my_key.pem ubuntu@[VOTRE_IP_EC2]

# 2. Aller dans le projet
cd ~/DevOps-MLOps

# 3. Pull le code
git pull origin main

# 4. ExÃ©cuter le script de dÃ©ploiement
chmod +x deploy.sh
./deploy.sh
```

### DÃ©ploiement avec Docker sur EC2

```bash
# Sur l'instance EC2
cd ~/DevOps-MLOps

# Construire l'image
docker build -f docker/Dockerfile -t credit-scoring-api .

# Lancer le conteneur
docker run -d -p 5000:5000 --name credit-api --restart unless-stopped credit-scoring-api

# VÃ©rifier les logs
docker logs credit-api

# Tester l'API
curl http://localhost:5000/health
```

### AccÃ¨s Ã  l'API DÃ©ployÃ©e

Une fois dÃ©ployÃ©e, l'API est accessible sur :
```
http://[VOTRE_IP_EC2]:5000
```

**Important** : Assurez-vous que le Security Group EC2 autorise le trafic sur le port 5000.

## ğŸ” Workflow complet

1. **Exploration** : Analyser les donnÃ©es dans `notebooks/model_train.ipynb`
2. **Preprocessing** : PrÃ©parer les donnÃ©es (encodage, normalisation)
3. **EntraÃ®nement** : EntraÃ®ner le modÃ¨le XGBoost
4. **Sauvegarde** : Sauvegarder le modÃ¨le dans `model/`
5. **API** : Exposer le modÃ¨le via l'API Flask
6. **Tests** : Valider le fonctionnement avec les tests unitaires
7. **CI/CD** : Tests automatiques avec GitHub Actions
8. **DÃ©ploiement** : DÃ©ploiement automatique sur EC2 Ã  chaque push

## ğŸ“ Notes importantes

- Le modÃ¨le attend **23 features prÃ©-traitÃ©es** (normalisÃ©es et encodÃ©es)
- Les donnÃ©es doivent Ãªtre au format JSON avec **toutes les colonnes requises**
- Le modÃ¨le est chargÃ© au dÃ©marrage de l'API
- Les variables numÃ©riques doivent Ãªtre normalisÃ©es (StandardScaler)
- Les variables catÃ©gorielles doivent Ãªtre encodÃ©es (one-hot avec drop='first')

## ğŸ“š Documentation

Des captures d'Ã©cran et de la documentation supplÃ©mentaire sont disponibles dans le dossier `docs/`.

## ğŸ” SÃ©curitÃ©

- Les clÃ©s SSH et les informations sensibles sont stockÃ©es dans les secrets GitHub
- Le fichier `.gitignore` exclut les fichiers sensibles (`my_key.pem`, `.env`, etc.)
- Les adresses IP publiques doivent Ãªtre masquÃ©es dans les captures d'Ã©cran et la documentation

## ğŸ“Š Architecture de DÃ©ploiement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GitHub    â”‚
â”‚  Repository â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Push
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GitHub      â”‚
â”‚ Actions CI  â”‚ â”€â”€â–º Tests, Build Docker
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Success
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GitHub      â”‚
â”‚ Actions CD  â”‚ â”€â”€â–º SSH to EC2
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Deploy
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AWS EC2   â”‚
â”‚  Instance   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Docker â”‚ â”‚ â”€â”€â–º API Flask
â”‚  â”‚Containerâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
  http://[IP]:5000
```

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Machine Learning** : XGBoost, scikit-learn, pandas
- **API** : Flask
- **Containerisation** : Docker
- **CI/CD** : GitHub Actions
- **Cloud** : AWS EC2
- **Version Control** : Git, GitHub